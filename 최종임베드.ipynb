{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken\n",
    "\n",
    "pip install AzureOpenAI\n",
    "\n",
    "import openai\n",
    "client = openai.AzureOpenAI(\n",
    "  api_key = \"ë³´ì•ˆ\",  \n",
    "  api_version = \"ë³´ì•ˆ\",\n",
    "  azure_endpoint = \"ë³´ì•ˆ\"\n",
    ")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from num2words import num2words\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "df=pd.read_csv(os.path.join(os.getcwd(),'2nd_project_data_final 1.csv')) # This assumes that you have placed the bill_sum_data.csv in the same directory you are running Jupyter Notebooks\n",
    "df\n",
    "\n",
    "\n",
    "df_inde = df[['id','name','nameHanja','movementFamily','orders','addressBirth','aliases','bornDied','references','content','activities','engagedOrganizations','isForeigner','image_url'\n",
    "]]\n",
    "\n",
    "df_inde\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ê²½ê³  ë„ê¸° (SettingWithCopyWarning ë°©ì§€)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# ì˜ˆì™¸ë¥¼ í¬í•¨í•œ í…ìŠ¤íŠ¸ ì •ê·œí™” í•¨ìˆ˜\n",
    "def normalize_text(s, sep_token=\" \\n \"):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"  # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬\n",
    "\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()         # ë‹¤ì¤‘ ê³µë°± ì œê±°\n",
    "    s = re.sub(r\"\\.\\s*,\", \"\", s)               # '. ,' íŒ¨í„´ ì œê±°\n",
    "    s = s.replace(\"..\", \".\")                   # '..' â†’ '.'\n",
    "    s = s.replace(\". .\", \".\")                  # '. .' â†’ '.'\n",
    "    s = s.replace(\"\\n\", \"\")                    # ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "# DataFrame ë¶ˆëŸ¬ì˜¨ í›„: text ì»¬ëŸ¼ ì „ì²˜ë¦¬\n",
    "# ì˜ˆ: df_inde = pd.read_csv(\"ë…ë¦½ìš´ë™ê°€.csv\")\n",
    "# ì „ì²˜ë¦¬ ì „ì— ê²°ì¸¡ì¹˜ ë¨¼ì € ì²˜ë¦¬\n",
    "df_inde['content'] = df_inde['content'].fillna(\"\")        # NaN â†’ ë¹ˆ ë¬¸ìì—´\n",
    "df_inde['content'] = df_inde['content'].apply(normalize_text)  # ì „ì²˜ë¦¬ ì ìš©\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df_inde['n_tokens'] = df_inde[\"content\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df_bills = df_inde[df_inde.n_tokens<8192]\n",
    "len(df_bills)\n",
    "\n",
    "\n",
    "df_inde = df_inde[df_inde.n_tokens < 8192]\n",
    "# df_inde.sort_values(by=\"n_tokens\", ascending=False).head(10)\n",
    "df_inde\n",
    "\n",
    "\n",
    "sample_encode = tokenizer.encode(df_inde.content[0]) \n",
    "decode = tokenizer.decode_tokens_bytes(sample_encode)\n",
    "decode\n",
    "\n",
    "len(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "client = AzureOpenAI (\n",
    "    api_key = \"ë³´ì•ˆ\",  \n",
    "    api_version = \"ë³´ì•ˆ\",\n",
    "    azure_endpoint = \"ë³´ì•ˆ\"\n",
    ")\n",
    "\n",
    "deployment_name = \"text-embedding-ada-002\"  # ì˜ˆ: \"embedding-v2\"\n",
    "\n",
    "# 2. ë°°ì¹˜ ì„ë² ë”© í•¨ìˆ˜\n",
    "def generate_embeddings_batch(text_list, model=deployment_name):\n",
    "    try:\n",
    "        response = client.embeddings.create(input=text_list, model=model)\n",
    "        return [item.embedding for item in response.data]\n",
    "    except Exception as e:\n",
    "        print(\"âŒ ë°°ì¹˜ ì„ë² ë”© ì‹¤íŒ¨:\", e)\n",
    "        return [None] * len(text_list)  # ì‹¤íŒ¨í•œ ê²½ìš° Noneìœ¼ë¡œ ì±„ì›€\n",
    "\n",
    "# 3. ë°ì´í„° ì¤€ë¹„\n",
    "df_inde = df_inde[df_inde['content'].apply(lambda x: isinstance(x, str) and x.strip() != \"\")]\n",
    "df_inde = df_inde[df_inde['n_tokens'] < 8192]\n",
    "df_inde = df_inde.reset_index(drop=True)\n",
    "\n",
    "# 4. ë°°ì¹˜ ì²˜ë¦¬ ë£¨í”„\n",
    "batch_size = 100\n",
    "all_embeddings = []\n",
    "\n",
    "for i in range(0, len(df_inde), batch_size):\n",
    "    batch_texts = df_inde['content'][i:i+batch_size].tolist()\n",
    "    print(f\"ğŸ”„ {i} ~ {i+len(batch_texts)-1} ì²˜ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    batch_embeddings = generate_embeddings_batch(batch_texts)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    time.sleep(1.2)  # ì†ë„ ì¡°ì ˆ (rate limit ë°©ì§€)\n",
    "\n",
    "# 5. ê²°ê³¼ ë¶™ì´ê¸°\n",
    "df_inde['ada_v2'] = all_embeddings\n",
    "\n",
    "# âœ… ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥\n",
    "print(f\"\\nğŸ‰ ì´ {len(df_inde)}ê±´ ì„ë² ë”© ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "\n",
    "\n",
    "df_inde.to_csv(\"ì„ë² ë”©_ì™„ë£Œ2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
