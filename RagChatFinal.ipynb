{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install openai pandas scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 🎯 임베딩용 Azure 클라이언트\n",
    "embedding_client = AzureOpenAI(\n",
    "  api_key = \"\",\n",
    "  api_version = \"\",\n",
    "  azure_endpoint = \"\"\n",
    ")\n",
    "\n",
    "\n",
    "# 🎯 챗용 Azure 클라이언트\n",
    "chat_client = AzureOpenAI(\n",
    "  api_key=\"\",\n",
    "  api_version=\"\",\n",
    "  azure_endpoint=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#✅ 2. CSV 로딩 함수\n",
    "\n",
    "def load_embedded_csv(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ada_v2'] = df['ada_v2'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#✅ 3. 임베딩 함수\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    response = embedding_client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#✅ 4. 유사 문서 검색 / name 인식 / 필터를 추가 / 이름 출력(최종)\n",
    "\n",
    "def filter_df_by_query(query, df):\n",
    "    # ① 이름 기반 필터 우선 적용\n",
    "    name_filtered = df[df['name'].str.contains(query, na=False)]\n",
    "\n",
    "    if not name_filtered.empty:\n",
    "        print(\"✅ 이름 기반 필터링 적용:\", name_filtered['name'].tolist())\n",
    "        return name_filtered\n",
    "\n",
    "    # ② 다중 필드 기반 필터\n",
    "    multi_filtered = df[\n",
    "        df['orders'].str.contains(query, na=False) |\n",
    "        df['movementFamily'].str.contains(query, na=False) |\n",
    "        df['activities'].str.contains(query, na=False) |\n",
    "        df['content'].str.contains(query, na=False)\n",
    "    ]\n",
    "\n",
    "    if not multi_filtered.empty:\n",
    "        print(\"✅ 다중 필드 기반 필터링 적용\")\n",
    "        return multi_filtered\n",
    "\n",
    "    print(\"⚠️ 필터링 실패 → 전체 데이터 사용\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def retrieve_relevant_context(query, df, top_k=3, embed_model=\"text-embedding-ada-002\"):\n",
    "    # 1. 질문 임베딩 생성\n",
    "    query_emb = generate_embeddings(query, model=embed_model)\n",
    "\n",
    "    # 2. 유사도 계산\n",
    "    df['score'] = df['ada_v2'].apply(lambda x: cosine_similarity([x], [query_emb])[0][0])\n",
    "\n",
    "    # ✅ 3. 이름 포함된 문서에는 점수 가중치 추가\n",
    "    df.loc[df['name'].str.contains(query, na=False), 'score'] += 1.0\n",
    "\n",
    "    # 4. Top-K 문서 선택\n",
    "    top_docs = df.sort_values(by=\"score\", ascending=False).head(top_k).reset_index()\n",
    "\n",
    "    context_blocks = []\n",
    "    citations = []\n",
    "\n",
    "    print(\"🔍 유사도 상위 문서 (Top {}):\".format(top_k))\n",
    "    for i, row in top_docs.iterrows():\n",
    "        ref_id = f\"[{i+1}]\"\n",
    "        name = row.get(\"name\", \"\")\n",
    "        score = round(row[\"score\"], 4)\n",
    "        print(f\"{ref_id} {name} (score: {score})\")\n",
    "\n",
    "        # GPT에 넘길 문서 블록 구성\n",
    "        text = f\"\"\"{ref_id}\n",
    "        이름: {name}\n",
    "        한자: {row.get(\"nameHanja\", \"\")}\n",
    "        출생지: {row.get(\"addressBirth\", \"\")}\n",
    "        훈격: {row.get(\"orders\", \"\")}\n",
    "        독립운동 분야: {row.get(\"movementFamily\", \"\")}\n",
    "        주요 활동: {row.get(\"activities\", \"\")}\n",
    "        관련 단체: {row.get(\"engagedOrganizations\", \"\")}\n",
    "        내용: {row['content']}\n",
    "        \"\"\"\n",
    "        context_blocks.append(text)\n",
    "\n",
    "        # Citation 구성\n",
    "        citation_info = {\n",
    "            \"index\": i + 1,\n",
    "            \"title\": name,\n",
    "            \"reference\": row.get(\"references\")\n",
    "        }\n",
    "        citations.append(citation_info)\n",
    "\n",
    "    context = \"\\n\\n\".join(context_blocks)\n",
    "    return context, citations\n",
    "\n",
    "\n",
    "def rag_chatbot(\n",
    "    query,\n",
    "    df,\n",
    "    top_k=5,\n",
    "    embed_model=\"text-embedding-ada-002\",\n",
    "    chat_model=\"gpt-4o\",\n",
    "    system_prompt=\"너는 독립운동 전문가야. 문서 내 '이름'과 사용자 질문을 비교해서 정확히 답변해줘.\"\n",
    "):\n",
    "    # 1. 필터링\n",
    "    filtered_df = filter_df_by_query(query, df)\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"⚠️ 이름/내용 필터링 실패 → 전체 데이터 사용\")\n",
    "        filtered_df = df\n",
    "\n",
    "    # 2. 유사도 기반 context 생성\n",
    "    context, citations = retrieve_relevant_context(query, filtered_df, top_k=top_k, embed_model=embed_model)\n",
    "    \n",
    "    # 3. GPT 호출\n",
    "    response = chat_client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"질문: {query}\\n\\n아래 문서를 참고해서 대답해줘:\\n\\n{context}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 4. 결과 출력\n",
    "    content_text = response.choices[0].message.content\n",
    "\n",
    "    print(\"🤖 GPT 응답:\\n\")\n",
    "    print(content_text)\n",
    "\n",
    "    print(\"\\n📚 Citations:\")\n",
    "    for c in citations:\n",
    "        print(f\"[{c['index']}] {c['title']}\\n출처: {c['reference']}\\n\")\n",
    "\n",
    "    return content_text, citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#✅ 5. 챗 응답 함수\n",
    "def ask_gpt(query, context, model=\"gpt-4o\",system_prompt=\"너는 한국 독립운동 전문가야. 아래 문서를 참고해서 정확하게 대답해줘.\"):\n",
    "    response = chat_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"질문: {query}\\n\\n참고 문서:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"인물: {query}\\n\\n아래 문서를 참고해 이 인물에 대한 내용을 찾아줘.\\n\\n{context}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ✅ 사용 예시\n",
    "response, citations = rag_chatbot(\n",
    "    query=\"애국장과 관련있는 독립운동가 3인?\",\n",
    "    df=df,\n",
    "    embed_model=\"text-embedding-ada-002\",\n",
    "    chat_model=\"gpt-4o\",\n",
    "    top_k=5,  # ← top_k를 늘리면 더 넓은 문서 범위를 검색함\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    너는 한국 독립운동 인물 전문 AI야. 친절하고 생동감있게 이야기하듯 말해줘. 유사도 높은 인물 중심으로 내용을 대답해.\n",
    "    문서 중 '관련 인물', '활동 내역'에서 연결점을 찾아  \n",
    "    사용자가 물어본 인물과 연관된 다른 인물이 있다면 이름을 명확히 알려줘.\n",
    "\n",
    "    - 반드시 아래 제공된 문서들만 참고해서 대답해.  \n",
    "    - 문서에 없는 정보는 \"문서에 해당 내용이 없습니다.\"라고 분명히 말해줘.  \n",
    "    - 추론하거나 외부 지식을 추가하지 마.  \n",
    "    - 사용자의 질문이 인물, 활동, 상훈, 소속 단체, 관련 인물에 대한 것이면 해당 문서 필드를 찾아서 설명해줘.\n",
    "\n",
    "    연결된 근거가 없으면 '연관된 인물 정보는 문서에 없습니다'라고 답해줘.\n",
    "    \"\"\"\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
